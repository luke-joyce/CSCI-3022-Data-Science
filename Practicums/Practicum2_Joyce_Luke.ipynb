{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='top'></a>\n",
    "\n",
    "# CSCI 3022: Intro to Data Science - Fall 2019 Practicum 2\n",
    "***\n",
    "\n",
    "This practicum is due on Canvas by **11:59 PM on Wednesday December 11**. Your solutions to theoretical questions should be done in Markdown/MathJax directly below the associated question.  Your solutions to computational questions should include any specified Python code and results as well as written commentary on your conclusions.  \n",
    "\n",
    "**Here are the rules:** \n",
    "\n",
    "1. All work, code and analysis, must be your own. \n",
    "1. You may use your course notes, posted lecture slides, textbooks, in-class notebooks, and homework solutions as resources.  You may also search online for answers to general knowledge questions like the form of a probability distribution function or how to perform a particular operation in Python/Pandas. \n",
    "1. This is meant to be like a coding portion of your midterm exam. So, the instructional team will be much less helpful than we typically are with homework. For example, we will not check answers, help debug your code, and so on.\n",
    "1. If something is left open-ended, it is because we want to see how you approach the kinds of problems you will encounter in the wild, where it will not always be clear what sort of tests/methods should be applied. Feel free to ask clarifying questions though.\n",
    "2. You may **NOT** post to message boards or other online resources asking for help.\n",
    "3. You may **NOT** copy-paste solutions *from anywhere*.\n",
    "4. You may **NOT** collaborate with classmates or anyone else.\n",
    "5. In short, **your work must be your own**. It really is that simple.\n",
    "\n",
    "Violation of the above rules will result in an immediate academic sanction (*at the very least*, you will receive a 0 on this practicum or an F in the course, depending on severity), and a trip to the Honor Code Council.\n",
    "\n",
    "**By submitting this assignment, you agree to abide by the rules given above.**\n",
    "\n",
    "***\n",
    "\n",
    "**Name**:  \n",
    "\n",
    "***\n",
    "\n",
    "\n",
    "**NOTES**: \n",
    "\n",
    "- You may not use late days on the practicums nor can you drop your practicum grades. \n",
    "- If you have a question for us, post it as a **PRIVATE** message on Piazza.  If we decide that the question is appropriate for the entire class, then we will add it to a Practicum clarifications thread. \n",
    "- Do **NOT** load or use any Python packages that are not available in Anaconda 3.6. \n",
    "- Some problems with code may be autograded.  If we provide a function API **do not** change it.  If we do not provide a function API then you're free to structure your code however you like. \n",
    "- Submit only this Jupyter notebook to Canvas.  Do not compress it using tar, rar, zip, etc. \n",
    "- This should go without saying, but... For any question that asks you to calculate something, you **must show all work to receive credit**. Sparse or nonexistent work will receive sparse or nonexistent credit.\n",
    "\n",
    "---\n",
    "**Shortcuts:**  [Problem 1](#p1) | [Problem 2](#p2) | [Bottom](#bot)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from calendar import month_name, different_locale\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "from scipy.special import binom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "<a id='p1'></a>\n",
    "[Back to top](#top)\n",
    "\n",
    "### [40 points] Problem 1:  Amazon Forest Fires\n",
    "\n",
    "A non-profit orgranization is trying to protect the Amazon rain forest and has recruited you as their head data scientist. For your first task, they've given you a dataset with the number of fires in each state in the Amazon region during each month between 1998 and 2017. They would like to have a 95% confidence interval for the true median number of forest fires that occur in each state on a yearly basis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6454 entries, 0 to 6453\n",
      "Data columns (total 5 columns):\n",
      "year      6453 non-null object\n",
      "state     6452 non-null object\n",
      "month     6454 non-null object\n",
      "number    6448 non-null float64\n",
      "date      6450 non-null object\n",
      "dtypes: float64(1), object(4)\n",
      "memory usage: 252.2+ KB\n"
     ]
    }
   ],
   "source": [
    "#Starter Code\n",
    "df = pd.read_csv('amazon.csv', thousands='.', decimal ='/', engine='python')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part A:**  This dataset isn't paticularly useful in it's current state, so we'll need to clean it up a bit. Some data scientists say that most of their job is to wrangle data, so this will give you a taste of cleaning a real world data set. Perform the following tasks:\n",
    "1. Drop the 'date' column. The only information this column holds is the year, which we already have in another column. \n",
    "2. Drop any rows with null values in any of the remaining columns\n",
    "3. Print all the unique values of the 'month' column. You'll notice that one is encoded with a differant character encoding then the format that pandas is using.\n",
    "3. Convert the Portugese month names to English month names. We've included the 'month_name' and the 'different_encoding' modules of the python calendar library in the top cell above, if you would like to use them. There are many ways to accomplish this task, and these modules are not required, but may make things easier. As part of this step, you should make sure that the Portugese month with the encoding problem is translated to the correct English month. \n",
    "4. Check the number column for any values that seem impossible. Drop any negative or fractional values, or any values over 50,000. 50,000 is large enough that no Brazilian state would ever have that many forest fires in one month, so we should get rid of anything above 50000. \n",
    "5. Since you're new on the job, some of your co-workers may have played a prank on you... Print out all the unique values of the 'year' column and drop any rows with values that don't make sense.\n",
    "6. Find the total number of rows remaining after you've done all of the above and write it out in a markdown cell. if you have correctly performed all of the tasks above, your dataframe should now have 6438 rows.\n",
    "\n",
    "**NOTE:** Since some of these tasks are not totally trivial, you may use any resources other than your classmates on this part of this problem. This means you may consult google, stack overflow, the python/pandas documentation, some random book on pandas you might have, etc... But you may not consult your classmates for help. ***CITE ALL RESOURCES USED IN A CODE COMMENT. A URL OR A BOOK TITLE IS SUFFICIENT. ANY CODE OBIVOUSLY COPIED FROM OUTSIDE SOURCES WITH OUT A CITATION WILL EARN YOU NO CREDIT ON THIS PROBLEM. YOU ARE ALLOWED TO USE THESE RESOURCES ONLY ON THIS PART OF THIS PROBLEM!***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~\n",
      "Months:\n",
      "Janeiro\n",
      "Fevereiro\n",
      "Marï¿½o\n",
      "Abril\n",
      "Maio\n",
      "Junho\n",
      "Julho\n",
      "Agosto\n",
      "Setembro\n",
      "Outubro\n",
      "Novembro\n",
      "Dezembro\n",
      "~~~~~~~~~~\n",
      "Number of rows: 6438\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>state</th>\n",
       "      <th>month</th>\n",
       "      <th>number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1998</td>\n",
       "      <td>Acre</td>\n",
       "      <td>January</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1999</td>\n",
       "      <td>Acre</td>\n",
       "      <td>January</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000</td>\n",
       "      <td>Acre</td>\n",
       "      <td>January</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2001</td>\n",
       "      <td>Acre</td>\n",
       "      <td>January</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2002</td>\n",
       "      <td>Acre</td>\n",
       "      <td>January</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2003</td>\n",
       "      <td>Acre</td>\n",
       "      <td>January</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2004</td>\n",
       "      <td>Acre</td>\n",
       "      <td>January</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2005</td>\n",
       "      <td>Acre</td>\n",
       "      <td>January</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2006</td>\n",
       "      <td>Acre</td>\n",
       "      <td>January</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2007</td>\n",
       "      <td>Acre</td>\n",
       "      <td>January</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2008</td>\n",
       "      <td>Acre</td>\n",
       "      <td>January</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2009</td>\n",
       "      <td>Acre</td>\n",
       "      <td>January</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2010</td>\n",
       "      <td>Acre</td>\n",
       "      <td>January</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2011</td>\n",
       "      <td>Acre</td>\n",
       "      <td>January</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2012</td>\n",
       "      <td>Acre</td>\n",
       "      <td>January</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2013</td>\n",
       "      <td>Acre</td>\n",
       "      <td>January</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2014</td>\n",
       "      <td>Acre</td>\n",
       "      <td>January</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2015</td>\n",
       "      <td>Acre</td>\n",
       "      <td>January</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2016</td>\n",
       "      <td>Acre</td>\n",
       "      <td>January</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2017</td>\n",
       "      <td>Acre</td>\n",
       "      <td>January</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1998</td>\n",
       "      <td>Acre</td>\n",
       "      <td>February</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1999</td>\n",
       "      <td>Acre</td>\n",
       "      <td>February</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2000</td>\n",
       "      <td>Acre</td>\n",
       "      <td>February</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2001</td>\n",
       "      <td>Acre</td>\n",
       "      <td>February</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2002</td>\n",
       "      <td>Acre</td>\n",
       "      <td>February</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2003</td>\n",
       "      <td>Acre</td>\n",
       "      <td>February</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2004</td>\n",
       "      <td>Acre</td>\n",
       "      <td>February</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2005</td>\n",
       "      <td>Acre</td>\n",
       "      <td>February</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2006</td>\n",
       "      <td>Acre</td>\n",
       "      <td>February</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2007</td>\n",
       "      <td>Acre</td>\n",
       "      <td>February</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6424</th>\n",
       "      <td>2007</td>\n",
       "      <td>Tocantins</td>\n",
       "      <td>November</td>\n",
       "      <td>147.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6425</th>\n",
       "      <td>2008</td>\n",
       "      <td>Tocantins</td>\n",
       "      <td>November</td>\n",
       "      <td>104.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6426</th>\n",
       "      <td>2009</td>\n",
       "      <td>Tocantins</td>\n",
       "      <td>November</td>\n",
       "      <td>251.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6427</th>\n",
       "      <td>2010</td>\n",
       "      <td>Tocantins</td>\n",
       "      <td>November</td>\n",
       "      <td>283.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6428</th>\n",
       "      <td>2011</td>\n",
       "      <td>Tocantins</td>\n",
       "      <td>November</td>\n",
       "      <td>144.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6429</th>\n",
       "      <td>2012</td>\n",
       "      <td>Tocantins</td>\n",
       "      <td>November</td>\n",
       "      <td>179.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6430</th>\n",
       "      <td>2013</td>\n",
       "      <td>Tocantins</td>\n",
       "      <td>November</td>\n",
       "      <td>345.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6431</th>\n",
       "      <td>2014</td>\n",
       "      <td>Tocantins</td>\n",
       "      <td>November</td>\n",
       "      <td>451.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6432</th>\n",
       "      <td>2015</td>\n",
       "      <td>Tocantins</td>\n",
       "      <td>November</td>\n",
       "      <td>833.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6433</th>\n",
       "      <td>2016</td>\n",
       "      <td>Tocantins</td>\n",
       "      <td>November</td>\n",
       "      <td>623.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6434</th>\n",
       "      <td>2017</td>\n",
       "      <td>Tocantins</td>\n",
       "      <td>November</td>\n",
       "      <td>434.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6435</th>\n",
       "      <td>1998</td>\n",
       "      <td>Tocantins</td>\n",
       "      <td>December</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6436</th>\n",
       "      <td>1999</td>\n",
       "      <td>Tocantins</td>\n",
       "      <td>December</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6437</th>\n",
       "      <td>2000</td>\n",
       "      <td>Tocantins</td>\n",
       "      <td>December</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6438</th>\n",
       "      <td>2001</td>\n",
       "      <td>Tocantins</td>\n",
       "      <td>December</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6439</th>\n",
       "      <td>2002</td>\n",
       "      <td>Tocantins</td>\n",
       "      <td>December</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6440</th>\n",
       "      <td>2003</td>\n",
       "      <td>Tocantins</td>\n",
       "      <td>December</td>\n",
       "      <td>109.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6441</th>\n",
       "      <td>2004</td>\n",
       "      <td>Tocantins</td>\n",
       "      <td>December</td>\n",
       "      <td>96.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6442</th>\n",
       "      <td>2005</td>\n",
       "      <td>Tocantins</td>\n",
       "      <td>December</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6443</th>\n",
       "      <td>2006</td>\n",
       "      <td>Tocantins</td>\n",
       "      <td>December</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6444</th>\n",
       "      <td>2007</td>\n",
       "      <td>Tocantins</td>\n",
       "      <td>December</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6445</th>\n",
       "      <td>2008</td>\n",
       "      <td>Tocantins</td>\n",
       "      <td>December</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6446</th>\n",
       "      <td>2009</td>\n",
       "      <td>Tocantins</td>\n",
       "      <td>December</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6447</th>\n",
       "      <td>2010</td>\n",
       "      <td>Tocantins</td>\n",
       "      <td>December</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6448</th>\n",
       "      <td>2011</td>\n",
       "      <td>Tocantins</td>\n",
       "      <td>December</td>\n",
       "      <td>105.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6449</th>\n",
       "      <td>2012</td>\n",
       "      <td>Tocantins</td>\n",
       "      <td>December</td>\n",
       "      <td>128.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6450</th>\n",
       "      <td>2013</td>\n",
       "      <td>Tocantins</td>\n",
       "      <td>December</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6451</th>\n",
       "      <td>2014</td>\n",
       "      <td>Tocantins</td>\n",
       "      <td>December</td>\n",
       "      <td>223.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6452</th>\n",
       "      <td>2015</td>\n",
       "      <td>Tocantins</td>\n",
       "      <td>December</td>\n",
       "      <td>373.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6453</th>\n",
       "      <td>2016</td>\n",
       "      <td>Tocantins</td>\n",
       "      <td>December</td>\n",
       "      <td>119.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6438 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      year      state     month  number\n",
       "0     1998       Acre   January     0.0\n",
       "1     1999       Acre   January     0.0\n",
       "2     2000       Acre   January     0.0\n",
       "3     2001       Acre   January     0.0\n",
       "4     2002       Acre   January     0.0\n",
       "5     2003       Acre   January    10.0\n",
       "6     2004       Acre   January     0.0\n",
       "7     2005       Acre   January    12.0\n",
       "8     2006       Acre   January     4.0\n",
       "9     2007       Acre   January     0.0\n",
       "10    2008       Acre   January     0.0\n",
       "11    2009       Acre   January     0.0\n",
       "12    2010       Acre   January     1.0\n",
       "13    2011       Acre   January     0.0\n",
       "14    2012       Acre   January     0.0\n",
       "15    2013       Acre   January     0.0\n",
       "16    2014       Acre   January     0.0\n",
       "17    2015       Acre   January     1.0\n",
       "18    2016       Acre   January    12.0\n",
       "19    2017       Acre   January     0.0\n",
       "20    1998       Acre  February     0.0\n",
       "21    1999       Acre  February     0.0\n",
       "22    2000       Acre  February     0.0\n",
       "23    2001       Acre  February     0.0\n",
       "24    2002       Acre  February     1.0\n",
       "25    2003       Acre  February     0.0\n",
       "26    2004       Acre  February     3.0\n",
       "27    2005       Acre  February     0.0\n",
       "28    2006       Acre  February     0.0\n",
       "29    2007       Acre  February     5.0\n",
       "...    ...        ...       ...     ...\n",
       "6424  2007  Tocantins  November   147.0\n",
       "6425  2008  Tocantins  November   104.0\n",
       "6426  2009  Tocantins  November   251.0\n",
       "6427  2010  Tocantins  November   283.0\n",
       "6428  2011  Tocantins  November   144.0\n",
       "6429  2012  Tocantins  November   179.0\n",
       "6430  2013  Tocantins  November   345.0\n",
       "6431  2014  Tocantins  November   451.0\n",
       "6432  2015  Tocantins  November   833.0\n",
       "6433  2016  Tocantins  November   623.0\n",
       "6434  2017  Tocantins  November   434.0\n",
       "6435  1998  Tocantins  December     9.0\n",
       "6436  1999  Tocantins  December    16.0\n",
       "6437  2000  Tocantins  December    20.0\n",
       "6438  2001  Tocantins  December    21.0\n",
       "6439  2002  Tocantins  December    39.0\n",
       "6440  2003  Tocantins  December   109.0\n",
       "6441  2004  Tocantins  December    96.0\n",
       "6442  2005  Tocantins  December    53.0\n",
       "6443  2006  Tocantins  December    15.0\n",
       "6444  2007  Tocantins  December    13.0\n",
       "6445  2008  Tocantins  December     7.0\n",
       "6446  2009  Tocantins  December    46.0\n",
       "6447  2010  Tocantins  December    72.0\n",
       "6448  2011  Tocantins  December   105.0\n",
       "6449  2012  Tocantins  December   128.0\n",
       "6450  2013  Tocantins  December    85.0\n",
       "6451  2014  Tocantins  December   223.0\n",
       "6452  2015  Tocantins  December   373.0\n",
       "6453  2016  Tocantins  December   119.0\n",
       "\n",
       "[6438 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "\n",
    "#1\n",
    "newdf = df.drop(columns=['date'], axis=1)\n",
    "\n",
    "#2\n",
    "newdf = newdf.dropna(subset=['year', 'state', 'month', 'number'])\n",
    "\n",
    "#3\n",
    "listOfMonths = newdf.month.unique()\n",
    "print('~~~~~~~~~~')\n",
    "print('Months:',*listOfMonths, sep='\\n')\n",
    "print('~~~~~~~~~~')\n",
    "\n",
    "#4\n",
    "newdf.loc[newdf['month'] == 'Janeiro', ['month']] = 'January'\n",
    "newdf.loc[newdf['month'] == 'Fevereiro', ['month']] = 'February'\n",
    "newdf.loc[newdf['month'] == 'Marï¿½o', ['month']] = 'March'\n",
    "newdf.loc[newdf['month'] == 'Abril', ['month']] = 'April'\n",
    "newdf.loc[newdf['month'] == 'Maio', ['month']] = 'May'\n",
    "newdf.loc[newdf['month'] == 'Junho', ['month']] = 'June'\n",
    "newdf.loc[newdf['month'] == 'Julho', ['month']] = 'July'\n",
    "newdf.loc[newdf['month'] == 'Agosto', ['month']] = 'August'\n",
    "newdf.loc[newdf['month'] == 'Setembro', ['month']] = 'September'\n",
    "newdf.loc[newdf['month'] == 'Outubro', ['month']] = 'October'\n",
    "newdf.loc[newdf['month'] == 'Novembro', ['month']] = 'November'\n",
    "newdf.loc[newdf['month'] == 'Dezembro', ['month']] = 'December'\n",
    "\n",
    "#5\n",
    "newdf = newdf.drop(newdf[(newdf.number > 50000)].index)\n",
    "newdf = newdf.drop(newdf[(newdf.number < 0)].index)\n",
    "newdf = newdf.drop(newdf[newdf.number%1 != 0].index)\n",
    "\n",
    "#6\n",
    "newdf = newdf.drop(newdf[(newdf.year == '-40')].index)\n",
    "newdf = newdf.drop(newdf[(newdf.year == '1000bc')].index)\n",
    "newdf = newdf.drop(newdf[(newdf.year == '10bc')].index)\n",
    "newdf = newdf.drop(newdf[(newdf.year == \"our new data scientist won't notice this\")].index)\n",
    "newdf.year.unique()\n",
    "\n",
    "#7\n",
    "numRows = newdf.shape[0]\n",
    "print(\"Number of rows:\",numRows)\n",
    "newdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part B:** Extract the median number of forest fires per month, yearly, by state. Store these median values in the given python dictionary.\n",
    "\n",
    "For Example:\n",
    "\n",
    "If one year of one state had the following numbers of fires:\n",
    "\n",
    "Jan: 1\n",
    "\n",
    "Feb: 2\n",
    "\n",
    "Mar: 3\n",
    "\n",
    "Apr: 4\n",
    "\n",
    "May: 5\n",
    "\n",
    "Jun: 6\n",
    "\n",
    "Jul: 7\n",
    "\n",
    "Aug: 8\n",
    "\n",
    "Sep: 9\n",
    "\n",
    "Oct: 10\n",
    "\n",
    "Nov: 11\n",
    "\n",
    "Dec: 12\n",
    "\n",
    "Then the median number of forest fires per month would be 6.5 (the average of the two middle elements since this has an even length)\n",
    "\n",
    "If the state of \"test\" had 5 years of recorded data, with the following median forest fire values: \\[1, 2, 7, 9, 3\\],  then python dictionary should look like: \n",
    "\n",
    "\\{\n",
    "\n",
    "    \"test\": [1, 2, 7, 9, 3]\n",
    "    \n",
    "\\}\n",
    "\n",
    "Below we've given you one of the states values in a test, so you can ensure you are calculating the medians correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GIVEN DICTIONARY CODE\n",
    "median_num_fires_monthly_yearly = {\n",
    "    'Acre': None,\n",
    "    'Alagoas': None,\n",
    "    'Amapa': None,\n",
    "    'Amazonas': None,\n",
    "    'Bahia': None,\n",
    "    'Ceara': None,\n",
    "    'Distrito Federal': None,\n",
    "    'Espirito Santo': None,\n",
    "    'Goias': None,\n",
    "    'Maranhao': None,\n",
    "    'Mato Grosso': None,\n",
    "    'Minas Gerais': None,\n",
    "    'Para': None,\n",
    "    'Paraiba': None,\n",
    "    'Pernambuco': None,\n",
    "    'Piau': None,\n",
    "    'Rio': None,\n",
    "    'Rondonia': None,\n",
    "    'Roraima': None,\n",
    "    'Santa Catarina': None,\n",
    "    'Sao Paulo': None,\n",
    "    'Sergipe': None,\n",
    "    'Tocantins': None  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acre [1.5, 0.0, 1.0, 0.5, 1.0, 8.0, 7.0, 13.0, 6.0, 4.5, 0.0, 2.5, 6.0, 7.0, 5.0, 13.5, 12.0, 24.0, 33.5, 45.0]\n",
      "Alagoas [0.0, 4.0, 7.5, 3.0, 13.0, 12.5, 6.5, 11.5, 8.0, 4.5, 18.0, 21.5, 10.5, 20.0, 24.5, 14.5, 12.5, 36.0, 13.5, 8.5]\n",
      "Amapa [0.0, 1.5, 1.0, 0.5, 5.0, 8.0, 7.0, 3.0, 4.0, 0.0, 2.0, 4.0, 2.0, 4.0, 13.0, 2.5, 7.0, 9.5, 12.0, 3.0]\n",
      "Amazonas [4.0, 9.0, 55.5, 8.5, 30.5, 152.5, 107.5, 61.0, 21.5, 63.5, 24.0, 57.5, 119.5, 87.0, 62.5, 138.0, 138.0, 231.5, 433.0, 119.0]\n",
      "Bahia [52.0, 95.0, 92.5, 129.5, 376.5, 407.5, 299.5, 240.0, 227.0, 321.5, 253.0, 278.5, 261.5, 209.5, 400.0, 259.5, 233.5, 281.0, 376.5, 174.0]\n",
      "Ceara [38.5, 65.0, 17.0, 113.5, 54.0, 61.5, 22.5, 38.0, 36.5, 96.5, 22.0, 17.0, 132.5, 25.0, 161.5, 40.5, 81.0, 76.0, 112.0, 26.0]\n",
      "Distrito Federal [0.0, 1.5, 0.5, 0.5, 1.0, 0.5, 3.5, 2.0, 0.5, 2.5, 3.0, 2.0, 7.0, 1.5, 2.0, 2.0, 4.0, 1.5, 7.0, 6.0]\n",
      "Espirito Santo [4.5, 9.5, 5.0, 6.5, 10.5, 24.5, 4.5, 5.0, 10.5, 11.0, 6.5, 12.5, 8.5, 6.5, 22.5, 15.5, 17.5, 47.5, 48.5, 10.0]\n",
      "Goias [30.0, 180.0, 42.0, 67.0, 181.5, 148.5, 224.0, 154.0, 77.5, 86.5, 48.0, 96.5, 172.0, 103.5, 98.0, 166.5, 195.5, 228.0, 200.0, 135.0]\n",
      "Maranhao [176.0, 156.0, 163.5, 324.5, 750.5, 769.5, 1036.0, 840.5, 366.5, 657.5, 368.5, 259.5, 1148.5, 813.0, 620.5, 804.5, 1440.0, 1264.5, 1143.0, 885.0]\n",
      "Mato Grosso [91.0, 518.5, 217.0, 279.0, 935.0, 744.0, 743.0, 543.0, 289.0, 256.0, 185.0, 477.5, 601.0, 388.0, 457.5, 400.5, 340.0, 595.5, 984.0, 702.0]\n",
      "Minas Gerais [26.5, 122.0, 58.0, 72.5, 216.0, 235.0, 167.0, 134.0, 84.5, 169.5, 99.0, 150.5, 147.0, 152.0, 204.0, 147.0, 224.0, 244.0, 207.0, 136.0]\n",
      "Para [638.0, 766.0, 303.5, 375.0, 460.5, 1235.5, 4436.0, 1631.5, 509.0, 471.5, 407.5, 319.0, 934.5, 370.0, 526.5, 173.0, 572.0, 815.5, 1450.5, 679.0]\n",
      "Paraiba [3.0, 34.5, 50.0, 38.5, 63.0, 105.0, 75.5, 80.5, 60.0, 27.0, 40.0, 46.0, 39.0, 46.5, 58.0, 45.0, 65.0, 56.5, 67.5, 49.0]\n",
      "Pernambuco [3.0, 14.5, 10.5, 6.5, 21.5, 30.5, 21.0, 39.0, 29.5, 20.5, 40.0, 21.5, 40.0, 33.0, 55.0, 34.5, 30.5, 44.0, 21.5, 20.0]\n",
      "Piau [82.5, 60.5, 50.0, 158.5, 267.0, 247.5, 401.5, 308.0, 141.5, 310.0, 79.0, 190.5, 294.0, 412.0, 390.5, 312.0, 359.5, 454.5, 263.5, 193.0]\n",
      "Rio [1.0, 17.5, 10.5, 13.0, 15.0, 28.5, 45.5, 35.5, 22.5, 13.0, 18.0, 29.5, 23.5, 28.5, 41.0, 24.5, 50.0, 43.5, 37.0, 43.0]\n",
      "Rondonia [14.5, 9.0, 13.0, 18.0, 116.0, 144.0, 179.5, 126.0, 28.5, 43.0, 9.5, 15.0, 101.0, 92.0, 41.0, 65.5, 118.0, 200.5, 159.0, 192.0]\n",
      "Roraima [0.0, 12.5, 15.0, 44.5, 90.5, 20.5, 94.0, 71.5, 55.0, 12.0, 28.0, 135.0, 22.5, 78.0, 72.5, 62.5, 105.0, 172.0, 86.0, 51.0]\n",
      "Santa Catarina [0.0, 9.0, 20.0, 8.0, 32.0, 102.0, 83.5, 74.0, 43.0, 15.5, 29.0, 33.0, 21.0, 25.0, 42.0, 60.5, 44.0, 34.5, 54.5, 51.0]\n",
      "Sao Paulo [277.5, 449.0, 201.0, 189.5, 240.0, 134.5, 123.0, 187.5, 92.5, 92.5, 56.0, 75.0, 146.5, 111.5, 82.0, 113.5, 146.5, 98.0, 182.5, 107.0]\n",
      "Sergipe [0.0, 1.5, 0.0, 1.5, 4.0, 2.5, 7.5, 9.5, 4.0, 1.5, 1.0, 5.5, 1.0, 4.5, 11.5, 5.0, 5.5, 23.0, 9.5, 1.0]\n",
      "Tocantins [5.0, 32.5, 82.5, 74.0, 172.5, 127.5, 387.0, 253.5, 99.5, 198.5, 92.5, 171.0, 499.5, 249.0, 346.5, 359.0, 337.0, 672.5, 700.5, 576.0]\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "years = [str(i) for i in range(1998,2018)]\n",
    "#median_num_fires_monthly_yearly = newdf_medians_by_year.to_dict()\n",
    "for key in median_num_fires_monthly_yearly:\n",
    "    median_num_fires_monthly_yearly[key] = []\n",
    "    for i in years:\n",
    "        med = newdf[(newdf['year']==i)&(newdf['state']==key)].number.median()\n",
    "        median_num_fires_monthly_yearly[key].append(med)\n",
    "    \n",
    "    \n",
    "for key in median_num_fires_monthly_yearly:\n",
    "    \n",
    "    print(key, median_num_fires_monthly_yearly[key])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Given Test\n",
    "assert median_num_fires_monthly_yearly['Acre'] == \\\n",
    "[1.5, 0.0, 1.0, 0.5, 1.0, 8.0, 7.0, 13.0, 6.0, 4.5, 0.0, 2.5, 6.0, 7.0, 5.0, 13.5, 12.0, 24.0, 33.5, 45.0] \\\n",
    ", \"something is wrong here\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Acre': [1.5,\n",
      "          0.0,\n",
      "          1.0,\n",
      "          0.5,\n",
      "          1.0,\n",
      "          8.0,\n",
      "          7.0,\n",
      "          13.0,\n",
      "          6.0,\n",
      "          4.5,\n",
      "          0.0,\n",
      "          2.5,\n",
      "          6.0,\n",
      "          7.0,\n",
      "          5.0,\n",
      "          13.5,\n",
      "          12.0,\n",
      "          24.0,\n",
      "          33.5,\n",
      "          45.0],\n",
      " 'Alagoas': [0.0,\n",
      "             4.0,\n",
      "             7.5,\n",
      "             3.0,\n",
      "             13.0,\n",
      "             12.5,\n",
      "             6.5,\n",
      "             11.5,\n",
      "             8.0,\n",
      "             4.5,\n",
      "             18.0,\n",
      "             21.5,\n",
      "             10.5,\n",
      "             20.0,\n",
      "             24.5,\n",
      "             14.5,\n",
      "             12.5,\n",
      "             36.0,\n",
      "             13.5,\n",
      "             8.5],\n",
      " 'Amapa': [0.0,\n",
      "           1.5,\n",
      "           1.0,\n",
      "           0.5,\n",
      "           5.0,\n",
      "           8.0,\n",
      "           7.0,\n",
      "           3.0,\n",
      "           4.0,\n",
      "           0.0,\n",
      "           2.0,\n",
      "           4.0,\n",
      "           2.0,\n",
      "           4.0,\n",
      "           13.0,\n",
      "           2.5,\n",
      "           7.0,\n",
      "           9.5,\n",
      "           12.0,\n",
      "           3.0],\n",
      " 'Amazonas': [4.0,\n",
      "              9.0,\n",
      "              55.5,\n",
      "              8.5,\n",
      "              30.5,\n",
      "              152.5,\n",
      "              107.5,\n",
      "              61.0,\n",
      "              21.5,\n",
      "              63.5,\n",
      "              24.0,\n",
      "              57.5,\n",
      "              119.5,\n",
      "              87.0,\n",
      "              62.5,\n",
      "              138.0,\n",
      "              138.0,\n",
      "              231.5,\n",
      "              433.0,\n",
      "              119.0],\n",
      " 'Bahia': [52.0,\n",
      "           95.0,\n",
      "           92.5,\n",
      "           129.5,\n",
      "           376.5,\n",
      "           407.5,\n",
      "           299.5,\n",
      "           240.0,\n",
      "           227.0,\n",
      "           321.5,\n",
      "           253.0,\n",
      "           278.5,\n",
      "           261.5,\n",
      "           209.5,\n",
      "           400.0,\n",
      "           259.5,\n",
      "           233.5,\n",
      "           281.0,\n",
      "           376.5,\n",
      "           174.0],\n",
      " 'Ceara': [38.5,\n",
      "           65.0,\n",
      "           17.0,\n",
      "           113.5,\n",
      "           54.0,\n",
      "           61.5,\n",
      "           22.5,\n",
      "           38.0,\n",
      "           36.5,\n",
      "           96.5,\n",
      "           22.0,\n",
      "           17.0,\n",
      "           132.5,\n",
      "           25.0,\n",
      "           161.5,\n",
      "           40.5,\n",
      "           81.0,\n",
      "           76.0,\n",
      "           112.0,\n",
      "           26.0],\n",
      " 'Distrito Federal': [0.0,\n",
      "                      1.5,\n",
      "                      0.5,\n",
      "                      0.5,\n",
      "                      1.0,\n",
      "                      0.5,\n",
      "                      3.5,\n",
      "                      2.0,\n",
      "                      0.5,\n",
      "                      2.5,\n",
      "                      3.0,\n",
      "                      2.0,\n",
      "                      7.0,\n",
      "                      1.5,\n",
      "                      2.0,\n",
      "                      2.0,\n",
      "                      4.0,\n",
      "                      1.5,\n",
      "                      7.0,\n",
      "                      6.0],\n",
      " 'Espirito Santo': [4.5,\n",
      "                    9.5,\n",
      "                    5.0,\n",
      "                    6.5,\n",
      "                    10.5,\n",
      "                    24.5,\n",
      "                    4.5,\n",
      "                    5.0,\n",
      "                    10.5,\n",
      "                    11.0,\n",
      "                    6.5,\n",
      "                    12.5,\n",
      "                    8.5,\n",
      "                    6.5,\n",
      "                    22.5,\n",
      "                    15.5,\n",
      "                    17.5,\n",
      "                    47.5,\n",
      "                    48.5,\n",
      "                    10.0],\n",
      " 'Goias': [30.0,\n",
      "           180.0,\n",
      "           42.0,\n",
      "           67.0,\n",
      "           181.5,\n",
      "           148.5,\n",
      "           224.0,\n",
      "           154.0,\n",
      "           77.5,\n",
      "           86.5,\n",
      "           48.0,\n",
      "           96.5,\n",
      "           172.0,\n",
      "           103.5,\n",
      "           98.0,\n",
      "           166.5,\n",
      "           195.5,\n",
      "           228.0,\n",
      "           200.0,\n",
      "           135.0],\n",
      " 'Maranhao': [176.0,\n",
      "              156.0,\n",
      "              163.5,\n",
      "              324.5,\n",
      "              750.5,\n",
      "              769.5,\n",
      "              1036.0,\n",
      "              840.5,\n",
      "              366.5,\n",
      "              657.5,\n",
      "              368.5,\n",
      "              259.5,\n",
      "              1148.5,\n",
      "              813.0,\n",
      "              620.5,\n",
      "              804.5,\n",
      "              1440.0,\n",
      "              1264.5,\n",
      "              1143.0,\n",
      "              885.0],\n",
      " 'Mato Grosso': [91.0,\n",
      "                 518.5,\n",
      "                 217.0,\n",
      "                 279.0,\n",
      "                 935.0,\n",
      "                 744.0,\n",
      "                 743.0,\n",
      "                 543.0,\n",
      "                 289.0,\n",
      "                 256.0,\n",
      "                 185.0,\n",
      "                 477.5,\n",
      "                 601.0,\n",
      "                 388.0,\n",
      "                 457.5,\n",
      "                 400.5,\n",
      "                 340.0,\n",
      "                 595.5,\n",
      "                 984.0,\n",
      "                 702.0],\n",
      " 'Minas Gerais': [26.5,\n",
      "                  122.0,\n",
      "                  58.0,\n",
      "                  72.5,\n",
      "                  216.0,\n",
      "                  235.0,\n",
      "                  167.0,\n",
      "                  134.0,\n",
      "                  84.5,\n",
      "                  169.5,\n",
      "                  99.0,\n",
      "                  150.5,\n",
      "                  147.0,\n",
      "                  152.0,\n",
      "                  204.0,\n",
      "                  147.0,\n",
      "                  224.0,\n",
      "                  244.0,\n",
      "                  207.0,\n",
      "                  136.0],\n",
      " 'Para': [638.0,\n",
      "          766.0,\n",
      "          303.5,\n",
      "          375.0,\n",
      "          460.5,\n",
      "          1235.5,\n",
      "          4436.0,\n",
      "          1631.5,\n",
      "          509.0,\n",
      "          471.5,\n",
      "          407.5,\n",
      "          319.0,\n",
      "          934.5,\n",
      "          370.0,\n",
      "          526.5,\n",
      "          173.0,\n",
      "          572.0,\n",
      "          815.5,\n",
      "          1450.5,\n",
      "          679.0],\n",
      " 'Paraiba': [3.0,\n",
      "             34.5,\n",
      "             50.0,\n",
      "             38.5,\n",
      "             63.0,\n",
      "             105.0,\n",
      "             75.5,\n",
      "             80.5,\n",
      "             60.0,\n",
      "             27.0,\n",
      "             40.0,\n",
      "             46.0,\n",
      "             39.0,\n",
      "             46.5,\n",
      "             58.0,\n",
      "             45.0,\n",
      "             65.0,\n",
      "             56.5,\n",
      "             67.5,\n",
      "             49.0],\n",
      " 'Pernambuco': [3.0,\n",
      "                14.5,\n",
      "                10.5,\n",
      "                6.5,\n",
      "                21.5,\n",
      "                30.5,\n",
      "                21.0,\n",
      "                39.0,\n",
      "                29.5,\n",
      "                20.5,\n",
      "                40.0,\n",
      "                21.5,\n",
      "                40.0,\n",
      "                33.0,\n",
      "                55.0,\n",
      "                34.5,\n",
      "                30.5,\n",
      "                44.0,\n",
      "                21.5,\n",
      "                20.0],\n",
      " 'Piau': [82.5,\n",
      "          60.5,\n",
      "          50.0,\n",
      "          158.5,\n",
      "          267.0,\n",
      "          247.5,\n",
      "          401.5,\n",
      "          308.0,\n",
      "          141.5,\n",
      "          310.0,\n",
      "          79.0,\n",
      "          190.5,\n",
      "          294.0,\n",
      "          412.0,\n",
      "          390.5,\n",
      "          312.0,\n",
      "          359.5,\n",
      "          454.5,\n",
      "          263.5,\n",
      "          193.0],\n",
      " 'Rio': [1.0,\n",
      "         17.5,\n",
      "         10.5,\n",
      "         13.0,\n",
      "         15.0,\n",
      "         28.5,\n",
      "         45.5,\n",
      "         35.5,\n",
      "         22.5,\n",
      "         13.0,\n",
      "         18.0,\n",
      "         29.5,\n",
      "         23.5,\n",
      "         28.5,\n",
      "         41.0,\n",
      "         24.5,\n",
      "         50.0,\n",
      "         43.5,\n",
      "         37.0,\n",
      "         43.0],\n",
      " 'Rondonia': [14.5,\n",
      "              9.0,\n",
      "              13.0,\n",
      "              18.0,\n",
      "              116.0,\n",
      "              144.0,\n",
      "              179.5,\n",
      "              126.0,\n",
      "              28.5,\n",
      "              43.0,\n",
      "              9.5,\n",
      "              15.0,\n",
      "              101.0,\n",
      "              92.0,\n",
      "              41.0,\n",
      "              65.5,\n",
      "              118.0,\n",
      "              200.5,\n",
      "              159.0,\n",
      "              192.0],\n",
      " 'Roraima': [0.0,\n",
      "             12.5,\n",
      "             15.0,\n",
      "             44.5,\n",
      "             90.5,\n",
      "             20.5,\n",
      "             94.0,\n",
      "             71.5,\n",
      "             55.0,\n",
      "             12.0,\n",
      "             28.0,\n",
      "             135.0,\n",
      "             22.5,\n",
      "             78.0,\n",
      "             72.5,\n",
      "             62.5,\n",
      "             105.0,\n",
      "             172.0,\n",
      "             86.0,\n",
      "             51.0],\n",
      " 'Santa Catarina': [0.0,\n",
      "                    9.0,\n",
      "                    20.0,\n",
      "                    8.0,\n",
      "                    32.0,\n",
      "                    102.0,\n",
      "                    83.5,\n",
      "                    74.0,\n",
      "                    43.0,\n",
      "                    15.5,\n",
      "                    29.0,\n",
      "                    33.0,\n",
      "                    21.0,\n",
      "                    25.0,\n",
      "                    42.0,\n",
      "                    60.5,\n",
      "                    44.0,\n",
      "                    34.5,\n",
      "                    54.5,\n",
      "                    51.0],\n",
      " 'Sao Paulo': [277.5,\n",
      "               449.0,\n",
      "               201.0,\n",
      "               189.5,\n",
      "               240.0,\n",
      "               134.5,\n",
      "               123.0,\n",
      "               187.5,\n",
      "               92.5,\n",
      "               92.5,\n",
      "               56.0,\n",
      "               75.0,\n",
      "               146.5,\n",
      "               111.5,\n",
      "               82.0,\n",
      "               113.5,\n",
      "               146.5,\n",
      "               98.0,\n",
      "               182.5,\n",
      "               107.0],\n",
      " 'Sergipe': [0.0,\n",
      "             1.5,\n",
      "             0.0,\n",
      "             1.5,\n",
      "             4.0,\n",
      "             2.5,\n",
      "             7.5,\n",
      "             9.5,\n",
      "             4.0,\n",
      "             1.5,\n",
      "             1.0,\n",
      "             5.5,\n",
      "             1.0,\n",
      "             4.5,\n",
      "             11.5,\n",
      "             5.0,\n",
      "             5.5,\n",
      "             23.0,\n",
      "             9.5,\n",
      "             1.0],\n",
      " 'Tocantins': [5.0,\n",
      "               32.5,\n",
      "               82.5,\n",
      "               74.0,\n",
      "               172.5,\n",
      "               127.5,\n",
      "               387.0,\n",
      "               253.5,\n",
      "               99.5,\n",
      "               198.5,\n",
      "               92.5,\n",
      "               171.0,\n",
      "               499.5,\n",
      "               249.0,\n",
      "               346.5,\n",
      "               359.0,\n",
      "               337.0,\n",
      "               672.5,\n",
      "               700.5,\n",
      "               576.0]}\n"
     ]
    }
   ],
   "source": [
    "#DONT CHANGE THIS. WE USE IT TO MAKE THE OUTPUT LEGIBLE FOR GRADING\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=1)\n",
    "pp.pprint(median_num_fires_monthly_yearly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part C:** Since we cannot rely on the central limit thereom for the median, we'll bootstrap some samples. Bootstrap 1000 samples for each state. Each bootstrapped sample should have 50 values drawn from the original sample.\n",
    "\n",
    "Find the median of each bootstrapped sample, and add it to a list. Save the list of median values for the states of **Sao Paulo** and **Goias**. We'll use them later to plot in part D. Then determine the 95% confidence interval of the true median from each list of bootstrapped medians for each state. Add a list of the low and high values of the confidence interval to the given python dictionary below. To help you check your work, the confidence interval of the state of Acre should be from roughly 4 to 7. Your values will change though, because each bootstrapped sample is picked randomly from the original.\n",
    "\n",
    "For Example:\n",
    "\n",
    "If the 95% confidence interval on the median is from 6 to 22 for the state of \"test\", then the dictionary would look like:\n",
    "\n",
    "{\n",
    "\n",
    "    \"test\": [6, 22]\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GIVEN CODE\n",
    "median_num_fires_bootstrap = {\n",
    "    'Acre': None,\n",
    "    'Alagoas': None,\n",
    "    'Amapa': None,\n",
    "    'Amazonas': None,\n",
    "    'Bahia': None,\n",
    "    'Ceara': None,\n",
    "    'Distrito Federal': None,\n",
    "    'Espirito Santo': None,\n",
    "    'Goias': None,\n",
    "    'Maranhao': None,\n",
    "    'Mato Grosso': None,\n",
    "    'Minas Gerais': None,\n",
    "    'Para': None,\n",
    "    'Paraiba': None,\n",
    "    'Pernambuco': None,\n",
    "    'Piau': None,\n",
    "    'Rio': None,\n",
    "    'Rondonia': None,\n",
    "    'Roraima': None,\n",
    "    'Santa Catarina': None,\n",
    "    'Sao Paulo': None,\n",
    "    'Sergipe': None,\n",
    "    'Tocantins': None  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here.\n",
    "saopaulo_and_goias={'Sao Paulo': None, \n",
    "                    'Goias' : None }\n",
    "\n",
    "for state in median_num_fires_monthly_yearly:\n",
    "        bootstrap_medians = [np.median(np.random.choice(median_num_fires_monthly_yearly[state], 50, replace=True)) \n",
    "                 for i in range(1000)]\n",
    "        if state == 'Sao Paulo' or state == 'Goias':\n",
    "            saopaulo_and_goias[state] = bootstrap_medians\n",
    "        CI_low = np.round(np.percentile(bootstrap_medians, 2.5), decimals = 2)\n",
    "        CI_hi = np.round(np.percentile(bootstrap_medians, 97.5), decimals = 2)\n",
    "        median_num_fires_bootstrap[state] = [CI_low, CI_hi]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Acre': [4.5, 7.0],\n",
      " 'Alagoas': [8.5, 13.0],\n",
      " 'Amapa': [2.5, 4.0],\n",
      " 'Amazonas': [57.48, 107.5],\n",
      " 'Bahia': [230.25, 278.5],\n",
      " 'Ceara': [37.5, 65.0],\n",
      " 'Distrito Federal': [1.5, 2.0],\n",
      " 'Espirito Santo': [8.5, 11.0],\n",
      " 'Goias': [98.0, 166.5],\n",
      " 'Maranhao': [620.5, 813.0],\n",
      " 'Mato Grosso': [388.0, 543.0],\n",
      " 'Minas Gerais': [136.0, 167.0],\n",
      " 'Para': [471.5, 679.0],\n",
      " 'Paraiba': [46.0, 58.01],\n",
      " 'Pernambuco': [21.5, 30.5],\n",
      " 'Piau': [193.0, 309.0],\n",
      " 'Rio': [22.5, 29.5],\n",
      " 'Rondonia': [34.75, 116.0],\n",
      " 'Roraima': [44.5, 74.75],\n",
      " 'Santa Catarina': [29.0, 43.0],\n",
      " 'Sao Paulo': [111.5, 146.5],\n",
      " 'Sergipe': [1.5, 5.0],\n",
      " 'Tocantins': [171.0, 337.0]}\n"
     ]
    }
   ],
   "source": [
    "#DONT CHANGE THIS. WE USE IT TO MAKE THE OUTPUT LEGIBLE FOR GRADING\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=1)\n",
    "pp.pprint(median_num_fires_bootstrap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part D:** Plot a histogram of the frequency of different median values for the two states **Sao Paulo** and **Goias**. Overlay these histograms on the same plot. Include axis labels, a title, a legend, etc. Choose two colors that work well together and provide enough contrast (e.g. No one can see gold overlayed with yellow), and use reasonable values of the **alpha** parameter so you can see both histograms. Plot two vertical lines that represent the outer bounds of the 95% confidence interval on the true median for each state, in the same color as the state. Does the data for the median look normally distributed? Why or why not? Does this validate our decision to not use the central limit theorem and instead bootstrap our median samples? Explain in a markdown cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(111.5, 92, 'Confidence interval for Sao Paulo')"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Your code here.\n",
    "\n",
    "\n",
    "CI_sanpaulo = median_num_fires_bootstrap['Sao Paulo']\n",
    "CI_goias = median_num_fires_bootstrap['Goias']\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(20,12))\n",
    "pd.Series(saopaulo_and_goias['Sao Paulo']).hist(ax=ax, color=\"green\", bins=15, density=False, alpha = 0.4)\n",
    "pd.Series(saopaulo_and_goias['Goias']).hist(ax=ax, color=\"red\", bins=15, density=False, alpha = 0.4)\n",
    "\n",
    "ax.grid(alpha=0.5)\n",
    "ax.set_axisbelow(True)\n",
    "\n",
    "ax.set_xlabel(\"Bootstrapped Estimates\", fontsize=15)\n",
    "ax.set_ylabel(\"Frequency\", fontsize=15)\n",
    "\n",
    "ax.hlines(y=110, xmin=CIG[0], xmax=CIG[1], linestyles = 'dashed', color='red')\n",
    "ax.text(CIG[0],112,'Confidence interval for Goias', fontsize=15)\n",
    "ax.hlines(y=90, xmin=CIS[0], xmax=CIS[1], linestyles = 'dashed', color='green')\n",
    "ax.text(CIS[0],92,'Confidence interval for Sao Paulo', fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "<a id='p2'></a>\n",
    "[Back to top](#top)\n",
    "\n",
    "### [40 points] Problem 2:  Sharknado Prediction\n",
    "\n",
    "Governor Hickenlooper has charged you with the task of assessing the factors associated with sharknado risk in Colorado. As everyone knows, sharknadoes are a leading cause of sharknado-related illness, and you are a world-renowned data/shark scientist.\n",
    "\n",
    "You decide to use multiple linear regression to understand and predict what factors lead to increased sharknado hazard. Your lead scientist, aptly named Fin, has collected lots of relevant data at a local sharknado hotspot, the Boulder Reservoir[\\*](#footnote). The data cover a variety of sharknado-related environmental and other conditions, and you'll find this data in the file `sharknadoes.csv`. \n",
    "\n",
    "**Response**: \n",
    "\n",
    "- $\\texttt{sharknado hazard}$: the hazard of a sharknado, where 1 is very unlikely and 100 is highly likely\n",
    "\n",
    "**Features**: \n",
    "\n",
    "- $\\texttt{taunts}$: the number of times over the past year that someone has taunted a shark\n",
    "- $\\texttt{clouds}$: what percentage of the sky was covered by clouds (fraction, 0-1)\n",
    "- $\\texttt{precipitation}$: amount of precipitation in the past 72 hours (inches)\n",
    "- $\\texttt{earthquake}$: the intensity of the most recent earthquake measured in the continental United States\n",
    "- $\\texttt{shark attacks}$: the number of shark attacks within 72 hours prior to the observation\n",
    "- $\\texttt{ice cream sold}$: the number of units of ice cream sold at the beach concession stand \n",
    "- $\\texttt{misery index}$: an economic indicator for how miserable the average United States citizen is, based on the unemployment rate and the inflation rate. More [here](https://www.stuffyoushouldknow.com/podcasts/whats-the-misery-index.htm) and [here](https://en.wikipedia.org/wiki/Misery_index_(economics)). Higher values correspond to more miserable citizens.\n",
    "- $\\texttt{temperature}$: the outside temperature, measured in degrees Fahrenheit\n",
    "- $\\texttt{humidity}$: relative humidity (percent, 0-100)\n",
    "- $\\texttt{pizzas sold}$: the number of pizzas sold at the beach concession stand in the past year\n",
    "- $\\texttt{pressure}$: local air pressure (millibar) \n",
    "- $\\texttt{octopuses}$: the number of octupuses in the vicinity on the day of the observation\n",
    "- $\\texttt{Zach's shoe size}$: the size of the shoes Zach was wearing when the observation was made\n",
    "- $\\texttt{Rachel's shoe size}$: the size of the shoes Rachel was wearing when the observation was made"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part A**: Read the data from `sharknadoes.csv` into a Pandas DataFrame.  Note that since we will be doing a multiple linear regression we will need all of the features. To make sure the data is \"clean\", drop any row in the DataFrame that is missing data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clouds</th>\n",
       "      <th>earthquake</th>\n",
       "      <th>pizzas sold</th>\n",
       "      <th>taunts</th>\n",
       "      <th>pressure</th>\n",
       "      <th>shark attacks</th>\n",
       "      <th>octopuses</th>\n",
       "      <th>precipitation</th>\n",
       "      <th>misery index</th>\n",
       "      <th>ice cream sold</th>\n",
       "      <th>humidity</th>\n",
       "      <th>temperature</th>\n",
       "      <th>Zachs shoe size</th>\n",
       "      <th>Rachels shoe size</th>\n",
       "      <th>sharknado hazard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.00</td>\n",
       "      <td>7.1</td>\n",
       "      <td>5560.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>847.12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.824059</td>\n",
       "      <td>12.987180</td>\n",
       "      <td>273.0</td>\n",
       "      <td>86.41</td>\n",
       "      <td>78.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>40.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.00</td>\n",
       "      <td>7.4</td>\n",
       "      <td>5179.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>844.34</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.993296</td>\n",
       "      <td>16.765435</td>\n",
       "      <td>184.0</td>\n",
       "      <td>96.67</td>\n",
       "      <td>89.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>36.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5227.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>839.48</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.173342</td>\n",
       "      <td>16.494518</td>\n",
       "      <td>141.0</td>\n",
       "      <td>53.85</td>\n",
       "      <td>65.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>19.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.13</td>\n",
       "      <td>7.9</td>\n",
       "      <td>5226.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>851.28</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.919291</td>\n",
       "      <td>8.277176</td>\n",
       "      <td>146.0</td>\n",
       "      <td>88.72</td>\n",
       "      <td>36.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>85.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.00</td>\n",
       "      <td>7.5</td>\n",
       "      <td>5491.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>852.67</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.729127</td>\n",
       "      <td>5.904750</td>\n",
       "      <td>178.0</td>\n",
       "      <td>63.08</td>\n",
       "      <td>72.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>56.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.89</td>\n",
       "      <td>8.1</td>\n",
       "      <td>5646.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>845.73</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.370010</td>\n",
       "      <td>8.585912</td>\n",
       "      <td>186.0</td>\n",
       "      <td>61.54</td>\n",
       "      <td>57.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>55.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.00</td>\n",
       "      <td>7.1</td>\n",
       "      <td>5476.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>851.98</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.900053</td>\n",
       "      <td>16.545501</td>\n",
       "      <td>259.0</td>\n",
       "      <td>87.44</td>\n",
       "      <td>79.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>52.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.40</td>\n",
       "      <td>6.8</td>\n",
       "      <td>4986.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>846.42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.876142</td>\n",
       "      <td>6.067241</td>\n",
       "      <td>105.0</td>\n",
       "      <td>67.18</td>\n",
       "      <td>41.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>9.5</td>\n",
       "      <td>53.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.00</td>\n",
       "      <td>6.1</td>\n",
       "      <td>5359.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>847.81</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.898160</td>\n",
       "      <td>6.789533</td>\n",
       "      <td>317.0</td>\n",
       "      <td>78.72</td>\n",
       "      <td>78.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>43.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.00</td>\n",
       "      <td>5.6</td>\n",
       "      <td>5404.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>847.81</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.909993</td>\n",
       "      <td>7.323839</td>\n",
       "      <td>285.0</td>\n",
       "      <td>79.74</td>\n",
       "      <td>81.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>44.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.79</td>\n",
       "      <td>8.1</td>\n",
       "      <td>5327.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>853.37</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.577133</td>\n",
       "      <td>16.604076</td>\n",
       "      <td>178.0</td>\n",
       "      <td>85.13</td>\n",
       "      <td>53.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>73.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.00</td>\n",
       "      <td>7.4</td>\n",
       "      <td>5202.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>851.98</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.558284</td>\n",
       "      <td>15.475781</td>\n",
       "      <td>287.0</td>\n",
       "      <td>72.56</td>\n",
       "      <td>77.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>56.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.00</td>\n",
       "      <td>5.5</td>\n",
       "      <td>5797.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>846.42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.316576</td>\n",
       "      <td>5.769055</td>\n",
       "      <td>263.0</td>\n",
       "      <td>52.05</td>\n",
       "      <td>87.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>35.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.61</td>\n",
       "      <td>5.9</td>\n",
       "      <td>5112.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>857.53</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.763867</td>\n",
       "      <td>14.292545</td>\n",
       "      <td>213.0</td>\n",
       "      <td>92.31</td>\n",
       "      <td>49.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>84.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.04</td>\n",
       "      <td>7.3</td>\n",
       "      <td>4974.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>841.56</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.142430</td>\n",
       "      <td>17.277318</td>\n",
       "      <td>92.0</td>\n",
       "      <td>77.69</td>\n",
       "      <td>31.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>49.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.00</td>\n",
       "      <td>6.3</td>\n",
       "      <td>5442.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>852.67</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.811097</td>\n",
       "      <td>19.577490</td>\n",
       "      <td>182.0</td>\n",
       "      <td>68.46</td>\n",
       "      <td>71.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>59.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.21</td>\n",
       "      <td>6.6</td>\n",
       "      <td>5310.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>851.98</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.160069</td>\n",
       "      <td>5.290798</td>\n",
       "      <td>96.0</td>\n",
       "      <td>64.10</td>\n",
       "      <td>38.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>82.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.57</td>\n",
       "      <td>7.5</td>\n",
       "      <td>5323.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>849.20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.282817</td>\n",
       "      <td>9.456465</td>\n",
       "      <td>122.0</td>\n",
       "      <td>89.49</td>\n",
       "      <td>49.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>9.5</td>\n",
       "      <td>67.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.00</td>\n",
       "      <td>7.3</td>\n",
       "      <td>4945.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>851.98</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.022405</td>\n",
       "      <td>13.338655</td>\n",
       "      <td>253.0</td>\n",
       "      <td>56.15</td>\n",
       "      <td>70.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>60.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.00</td>\n",
       "      <td>7.4</td>\n",
       "      <td>4974.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>849.89</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.734224</td>\n",
       "      <td>18.300784</td>\n",
       "      <td>171.0</td>\n",
       "      <td>56.41</td>\n",
       "      <td>60.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>65.37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    clouds  earthquake  pizzas sold  taunts  pressure  shark attacks  \\\n",
       "0     1.00         7.1       5560.0    15.0    847.12            2.0   \n",
       "1     1.00         7.4       5179.0    20.0    844.34            4.0   \n",
       "2     1.00         7.0       5227.0     0.0    839.48            9.0   \n",
       "3     0.13         7.9       5226.0    34.0    851.28            2.0   \n",
       "4     1.00         7.5       5491.0     6.0    852.67            2.0   \n",
       "6     0.89         8.1       5646.0    25.0    845.73            3.0   \n",
       "7     1.00         7.1       5476.0    16.0    851.98            2.0   \n",
       "9     0.40         6.8       4986.0    17.0    846.42            2.0   \n",
       "10    1.00         6.1       5359.0    15.0    847.81            2.0   \n",
       "11    1.00         5.6       5404.0    36.0    847.81            1.0   \n",
       "12    0.79         8.1       5327.0    11.0    853.37            2.0   \n",
       "13    1.00         7.4       5202.0    30.0    851.98            1.0   \n",
       "14    1.00         5.5       5797.0    28.0    846.42            2.0   \n",
       "15    0.61         5.9       5112.0    20.0    857.53            5.0   \n",
       "16    0.04         7.3       4974.0    32.0    841.56            6.0   \n",
       "17    1.00         6.3       5442.0    18.0    852.67            2.0   \n",
       "18    0.21         6.6       5310.0    30.0    851.98            1.0   \n",
       "19    0.57         7.5       5323.0    36.0    849.20            1.0   \n",
       "20    1.00         7.3       4945.0    28.0    851.98            2.0   \n",
       "21    1.00         7.4       4974.0    43.0    849.89            2.0   \n",
       "\n",
       "    octopuses  precipitation  misery index  ice cream sold  humidity  \\\n",
       "0         7.0       0.824059     12.987180           273.0     86.41   \n",
       "1         5.0       0.993296     16.765435           184.0     96.67   \n",
       "2         2.0       1.173342     16.494518           141.0     53.85   \n",
       "3         6.0       0.919291      8.277176           146.0     88.72   \n",
       "4         4.0       1.729127      5.904750           178.0     63.08   \n",
       "6         7.0       1.370010      8.585912           186.0     61.54   \n",
       "7         4.0       0.900053     16.545501           259.0     87.44   \n",
       "9         6.0       0.876142      6.067241           105.0     67.18   \n",
       "10        3.0       0.898160      6.789533           317.0     78.72   \n",
       "11        4.0       0.909993      7.323839           285.0     79.74   \n",
       "12        2.0       1.577133     16.604076           178.0     85.13   \n",
       "13        4.0       1.558284     15.475781           287.0     72.56   \n",
       "14        7.0       1.316576      5.769055           263.0     52.05   \n",
       "15        3.0       1.763867     14.292545           213.0     92.31   \n",
       "16        4.0       1.142430     17.277318            92.0     77.69   \n",
       "17        3.0       1.811097     19.577490           182.0     68.46   \n",
       "18        4.0       1.160069      5.290798            96.0     64.10   \n",
       "19        5.0       1.282817      9.456465           122.0     89.49   \n",
       "20        4.0       1.022405     13.338655           253.0     56.15   \n",
       "21        6.0       0.734224     18.300784           171.0     56.41   \n",
       "\n",
       "    temperature  Zachs shoe size  Rachels shoe size  sharknado hazard  \n",
       "0          78.0             42.0                9.0             40.22  \n",
       "1          89.0             42.0                9.5             36.42  \n",
       "2          65.0              9.5                9.0             19.54  \n",
       "3          36.0              9.5               10.0             85.00  \n",
       "4          72.0             42.0                9.0             56.34  \n",
       "6          57.0              9.5                9.0             55.42  \n",
       "7          79.0              9.5                9.0             52.66  \n",
       "9          41.0              9.5                9.5             53.68  \n",
       "10         78.0              9.5                9.0             43.84  \n",
       "11         81.0             42.0                9.0             44.83  \n",
       "12         53.0             42.0               10.0             73.30  \n",
       "13         77.0             42.0                9.5             56.11  \n",
       "14         87.0             42.0                9.0             35.41  \n",
       "15         49.0              9.5                9.0             84.31  \n",
       "16         31.0             42.0                9.5             49.91  \n",
       "17         71.0             42.0                9.0             59.27  \n",
       "18         38.0             42.0                9.0             82.03  \n",
       "19         49.0              9.5                9.5             67.10  \n",
       "20         70.0              9.5                9.0             60.17  \n",
       "21         60.0             42.0                9.0             65.37  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Your code here.\n",
    "df = pd.read_csv('sharknadoes.csv')\n",
    "df = df.dropna()\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part B**: Perform the appropriate statistical test at the $\\alpha = 0.025$ significance level to determine if _at least one_ of the features is related to the the response $y$.  Clearly describe your methodology and show all computations in Python. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>sharknado hazard</td> <th>  R-squared:         </th> <td>   0.978</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.972</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   179.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 11 Dec 2019</td> <th>  Prob (F-statistic):</th> <td>9.60e-42</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>21:05:42</td>     <th>  Log-Likelihood:    </th> <td> -174.23</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    72</td>      <th>  AIC:               </th> <td>   378.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    57</td>      <th>  BIC:               </th> <td>   412.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    14</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "          <td></td>             <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>             <td>-2549.8985</td> <td>   67.605</td> <td>  -37.718</td> <td> 0.000</td> <td>-2685.275</td> <td>-2414.522</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>clouds</th>            <td>   -1.5106</td> <td>    2.566</td> <td>   -0.589</td> <td> 0.558</td> <td>   -6.650</td> <td>    3.628</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>earthquake</th>        <td>    2.5079</td> <td>    0.467</td> <td>    5.367</td> <td> 0.000</td> <td>    1.572</td> <td>    3.444</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pizzas sold</th>       <td>   -0.0006</td> <td>    0.002</td> <td>   -0.373</td> <td> 0.711</td> <td>   -0.004</td> <td>    0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>taunts</th>            <td>    0.3117</td> <td>    0.042</td> <td>    7.447</td> <td> 0.000</td> <td>    0.228</td> <td>    0.396</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pressure</th>          <td>    3.0688</td> <td>    0.079</td> <td>   38.850</td> <td> 0.000</td> <td>    2.911</td> <td>    3.227</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>shark attacks</th>     <td>   -0.1151</td> <td>    0.144</td> <td>   -0.797</td> <td> 0.429</td> <td>   -0.404</td> <td>    0.174</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>octopuses</th>         <td>   -0.0749</td> <td>    0.143</td> <td>   -0.524</td> <td> 0.602</td> <td>   -0.361</td> <td>    0.211</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>precipitation</th>     <td>    1.3982</td> <td>    0.930</td> <td>    1.503</td> <td> 0.138</td> <td>   -0.464</td> <td>    3.261</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>misery index</th>      <td>    0.0273</td> <td>    0.080</td> <td>    0.340</td> <td> 0.735</td> <td>   -0.133</td> <td>    0.188</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ice cream sold</th>    <td>    0.0096</td> <td>    0.008</td> <td>    1.193</td> <td> 0.238</td> <td>   -0.007</td> <td>    0.026</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>humidity</th>          <td>    0.0188</td> <td>    0.027</td> <td>    0.706</td> <td> 0.483</td> <td>   -0.035</td> <td>    0.072</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>temperature</th>       <td>   -0.4426</td> <td>    0.053</td> <td>   -8.396</td> <td> 0.000</td> <td>   -0.548</td> <td>   -0.337</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Zachs shoe size</th>   <td>    0.0271</td> <td>    0.023</td> <td>    1.175</td> <td> 0.245</td> <td>   -0.019</td> <td>    0.073</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Rachels shoe size</th> <td>    0.2814</td> <td>    1.273</td> <td>    0.221</td> <td> 0.826</td> <td>   -2.268</td> <td>    2.831</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.821</td> <th>  Durbin-Watson:     </th> <td>   2.225</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.663</td> <th>  Jarque-Bera (JB):  </th> <td>   0.300</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.005</td> <th>  Prob(JB):          </th> <td>   0.861</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.316</td> <th>  Cond. No.          </th> <td>1.03e+06</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.03e+06. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:       sharknado hazard   R-squared:                       0.978\n",
       "Model:                            OLS   Adj. R-squared:                  0.972\n",
       "Method:                 Least Squares   F-statistic:                     179.4\n",
       "Date:                Wed, 11 Dec 2019   Prob (F-statistic):           9.60e-42\n",
       "Time:                        21:05:42   Log-Likelihood:                -174.23\n",
       "No. Observations:                  72   AIC:                             378.5\n",
       "Df Residuals:                      57   BIC:                             412.6\n",
       "Df Model:                          14                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=====================================================================================\n",
       "                        coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------------\n",
       "const             -2549.8985     67.605    -37.718      0.000   -2685.275   -2414.522\n",
       "clouds               -1.5106      2.566     -0.589      0.558      -6.650       3.628\n",
       "earthquake            2.5079      0.467      5.367      0.000       1.572       3.444\n",
       "pizzas sold          -0.0006      0.002     -0.373      0.711      -0.004       0.003\n",
       "taunts                0.3117      0.042      7.447      0.000       0.228       0.396\n",
       "pressure              3.0688      0.079     38.850      0.000       2.911       3.227\n",
       "shark attacks        -0.1151      0.144     -0.797      0.429      -0.404       0.174\n",
       "octopuses            -0.0749      0.143     -0.524      0.602      -0.361       0.211\n",
       "precipitation         1.3982      0.930      1.503      0.138      -0.464       3.261\n",
       "misery index          0.0273      0.080      0.340      0.735      -0.133       0.188\n",
       "ice cream sold        0.0096      0.008      1.193      0.238      -0.007       0.026\n",
       "humidity              0.0188      0.027      0.706      0.483      -0.035       0.072\n",
       "temperature          -0.4426      0.053     -8.396      0.000      -0.548      -0.337\n",
       "Zachs shoe size       0.0271      0.023      1.175      0.245      -0.019       0.073\n",
       "Rachels shoe size     0.2814      1.273      0.221      0.826      -2.268       2.831\n",
       "==============================================================================\n",
       "Omnibus:                        0.821   Durbin-Watson:                   2.225\n",
       "Prob(Omnibus):                  0.663   Jarque-Bera (JB):                0.300\n",
       "Skew:                           0.005   Prob(JB):                        0.861\n",
       "Kurtosis:                       3.316   Cond. No.                     1.03e+06\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.03e+06. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Your code here.\n",
    "features = df.loc[:,df.columns != \"sharknado hazard\"]\n",
    "response = df[\"sharknado hazard\"]\n",
    "features = sm.add_constant(features)\n",
    "full_model = sm.OLS(response, features).fit()\n",
    "full_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$H_0 = \\beta_1 = \\beta_2 = \\beta_3 = ... = \\beta_n = 0$\n",
    "\n",
    "$H_1 = \\beta_i \\neq 0$ for some i in (1, n)\n",
    "\n",
    "As seen in the first table, our p-value for the F-statistic is $9.60 \\times 10^{-42}$, which is less than the $\\alpha = 0.025$ significance level, meaning we can reject the null hypothesis and come to the conclusion that at least one of the features is related to response $y$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part C**: Write a function `backward_select(df, resp_str, maxsse)` that takes in the DataFrame (`df`), the name of the column corresponding to the response (`resp_str`), and the maximum desired sum of squared errors (`maxsse`), and returns a list of feature names corresponding to the most important features via backward selection.  Use your code to determine the reduced MLR model with the minimal number of features such that the SSE of the reduced model is less than 570. At each stage in backward selection you should remove the feature that has the highest p-value associated with the hypothesis test for the given slope coefficient $\\beta_k \\neq 0$.\n",
    "\n",
    "Your code should clearly indicate which feature was removed in each stage, and the SSE associated with the model fit before the feature's removal. _Specifically, please write your code to print the name of the feature that is going to be removed and the SSE before its removal_. Afterward, be sure to report all of the retained features and the SSE of the reduced model.\n",
    "\n",
    "**Note**: The point of this exercise is to see if you can implement **backward_select** yourself.  You may of course use canned routines like statmodels OLS, but you may not call any Python method that explicitly performs backward selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rachels shoe size , with SSE of 533.4003410558921 , removed at stage 1\n",
      "misery index , with SSE of 534.6875698945835 , removed at stage 2\n",
      "octopuses , with SSE of 536.5069911256901 , removed at stage 3\n",
      "clouds , with SSE of 539.49656163576 , removed at stage 4\n",
      "pizzas sold , with SSE of 543.357200472107 , removed at stage 5\n",
      "humidity , with SSE of 547.4141982866556 , removed at stage 6\n",
      "shark attacks , with SSE of 552.1548653819143 , removed at stage 7\n",
      "Zachs shoe size , with SSE of 564.1068895239198 , removed at stage 8\n",
      "Features left: ['earthquake', 'taunts', 'pressure', 'precipitation', 'ice cream sold', 'temperature']\n"
     ]
    }
   ],
   "source": [
    "def backward_select(df, resp_str, maxsse):\n",
    "    #Your code here.\n",
    "    response = df[resp_str]\n",
    "    important_features = list(df.columns[df.columns != resp_str])\n",
    "    sse = 0\n",
    "    m = df[important_features]\n",
    "    m = sm.add_constant(m)\n",
    "    model = sm.OLS(response, m).fit() \n",
    "    sse = np.sum((response-model.predict(m))**2)\n",
    "    \n",
    "    stage = 1\n",
    "    for i in range(maxsse):\n",
    "        r = model.pvalues.idxmax()   # candidate feature to remove is one with highest p-value\n",
    "        new_remaining_features = important_features.copy()\n",
    "        new_remaining_features.remove(r)\n",
    "        m = df[new_remaining_features]      # create feature set without the feature to remove\n",
    "        m = sm.add_constant(m)\n",
    "        model = sm.OLS(response, m).fit()\n",
    "        sse = np.sum((response-model.predict(m))**2) # SSE_reduced\n",
    "        \n",
    "        if sse < maxsse:\n",
    "            important_features.remove(r)\n",
    "            print(r,\", with SSE of\", sse, \", removed at stage\", stage)\n",
    "        stage += 1\n",
    "        \n",
    "    print(\"Features left:\",important_features)\n",
    "    \n",
    "    return important_features\n",
    "\n",
    "important_features = backward_select(df, \"sharknado hazard\", 570)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part D**: Write down the final multiple linear regression model, including estimated parameters, obtained by your backward selection process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>sharknado hazard</td> <th>  R-squared:         </th> <td>   0.977</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.974</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   450.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 11 Dec 2019</td> <th>  Prob (F-statistic):</th> <td>6.28e-51</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>23:58:51</td>     <th>  Log-Likelihood:    </th> <td> -176.27</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    72</td>      <th>  AIC:               </th> <td>   366.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    65</td>      <th>  BIC:               </th> <td>   382.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     6</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "         <td></td>           <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>          <td>-2542.0392</td> <td>   59.776</td> <td>  -42.526</td> <td> 0.000</td> <td>-2661.420</td> <td>-2422.659</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>earthquake</th>     <td>    2.4012</td> <td>    0.435</td> <td>    5.520</td> <td> 0.000</td> <td>    1.532</td> <td>    3.270</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>taunts</th>         <td>    0.3188</td> <td>    0.037</td> <td>    8.534</td> <td> 0.000</td> <td>    0.244</td> <td>    0.393</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pressure</th>       <td>    3.0618</td> <td>    0.071</td> <td>   42.836</td> <td> 0.000</td> <td>    2.919</td> <td>    3.205</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>precipitation</th>  <td>    1.2559</td> <td>    0.885</td> <td>    1.419</td> <td> 0.161</td> <td>   -0.512</td> <td>    3.023</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ice cream sold</th> <td>    0.0099</td> <td>    0.008</td> <td>    1.311</td> <td> 0.194</td> <td>   -0.005</td> <td>    0.025</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>temperature</th>    <td>   -0.4680</td> <td>    0.033</td> <td>  -14.220</td> <td> 0.000</td> <td>   -0.534</td> <td>   -0.402</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 1.389</td> <th>  Durbin-Watson:     </th> <td>   2.233</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.499</td> <th>  Jarque-Bera (JB):  </th> <td>   0.798</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.210</td> <th>  Prob(JB):          </th> <td>   0.671</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.300</td> <th>  Cond. No.          </th> <td>1.50e+05</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.5e+05. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:       sharknado hazard   R-squared:                       0.977\n",
       "Model:                            OLS   Adj. R-squared:                  0.974\n",
       "Method:                 Least Squares   F-statistic:                     450.3\n",
       "Date:                Wed, 11 Dec 2019   Prob (F-statistic):           6.28e-51\n",
       "Time:                        23:58:51   Log-Likelihood:                -176.27\n",
       "No. Observations:                  72   AIC:                             366.5\n",
       "Df Residuals:                      65   BIC:                             382.5\n",
       "Df Model:                           6                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==================================================================================\n",
       "                     coef    std err          t      P>|t|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------\n",
       "const          -2542.0392     59.776    -42.526      0.000   -2661.420   -2422.659\n",
       "earthquake         2.4012      0.435      5.520      0.000       1.532       3.270\n",
       "taunts             0.3188      0.037      8.534      0.000       0.244       0.393\n",
       "pressure           3.0618      0.071     42.836      0.000       2.919       3.205\n",
       "precipitation      1.2559      0.885      1.419      0.161      -0.512       3.023\n",
       "ice cream sold     0.0099      0.008      1.311      0.194      -0.005       0.025\n",
       "temperature       -0.4680      0.033    -14.220      0.000      -0.534      -0.402\n",
       "==============================================================================\n",
       "Omnibus:                        1.389   Durbin-Watson:                   2.233\n",
       "Prob(Omnibus):                  0.499   Jarque-Bera (JB):                0.798\n",
       "Skew:                           0.210   Prob(JB):                        0.671\n",
       "Kurtosis:                       3.300   Cond. No.                     1.50e+05\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.5e+05. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Your code here.\n",
    "response = df[\"sharknado hazard\"]\n",
    "reduced_features = df.loc[:, important_features]\n",
    "reduced_features = sm.add_constant(reduced_features)\n",
    "reduced_model = sm.OLS(response, reduced_features).fit()\n",
    "reduced_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$y = -2542.0392 + (2.40122\\cdot n_{\\text{earthquake}}) + (0.3188 \\cdot n_{\\text{taunts}}) + (3.0618 \\cdot n_{\\text{pressure}}) + (1.2559 \\cdot n_{\\text{precipitation}}) + (0.0099 \\cdot n_{\\text{ice cream sold}}) - (0.4680 \\cdot n_{\\text{temperature}})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part E**: Perform the appropriate statistical test at the $\\alpha = 0.025$ significance level to determine whether there is a statistically significant difference between the full model with all features and the reduced model obtained by backward selection in **Part D**. You may use output from your model fit above, but all calculations should be set up in Markdown/MathJax."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $\\beta_{F}$ be the set of $\\beta_{i}$ for features that are a part of the original model, and let $\\beta_{R}$ be the set of $\\beta_{i}$ for remaining features in the reduced model.\n",
    "\n",
    "$H_0 = \\beta_1 = \\beta_2 = \\beta_3 = ... = \\beta_n = 0 \\in (\\beta_{F} - \\beta_{R})$\n",
    "\n",
    "$H_1 = \\beta_i \\neq 0$ for some i in (1, n) $\\in (\\beta_{F} - \\beta_{R})$\n",
    "\n",
    "\n",
    "$\\frac{(\\text{SSE}_\\text{Reduced model} - \\text{SSE}_\\text{Full model})/({p - k})}{(\\text{SSE}_\\text{Full model})/({n - p - 1})}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSE for full model: 532.94\n",
      "SSE for reduced model: 564.11\n",
      "P(>F) =  0.9063234965603284\n",
      "RR: F > = 2.8406938969971707\n"
     ]
    }
   ],
   "source": [
    "#Calculate SSE for full  and reduced models\n",
    "full_SSE = np.sum((response-full_model.predict(features))**2)\n",
    "reduced_SSE = np.sum((response-reduced_model.predict(reduced_features))**2)\n",
    "\n",
    "#Partial F-test\n",
    "F = ((reduced_SSE - full_SSE)/(p-k))/((full_SSE)/(n-p-1))\n",
    "\n",
    "print(\"SSE for full model:\",np.round(full_SSE, decimals = 2))\n",
    "print(\"SSE for reduced model:\",np.round(reduced_SSE, decimals = 2))\n",
    "\n",
    "k = len(important_features) \n",
    "p = len(df.columns)-1\n",
    "n = len(df)\n",
    "\n",
    "p_val = 1 - stats.f.cdf(F, p-k, n-p-1)\n",
    "print(\"P(>F) = \",p_val)\n",
    "print(\"RR: F > =\",stats.f.ppf(1-.01, p-k, n-p-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part F**: Based on your conclusions in **Part E**, use the _better_ of the two models to predict the sharknado hazard when the following features are observed: \n",
    "\n",
    "- $\\texttt{taunts}$: 47\n",
    "- $\\texttt{clouds}$: 0.8\n",
    "- $\\texttt{precipitation}$: 1 inch\n",
    "- $\\texttt{earthquake}$: 5\n",
    "- $\\texttt{shark attacks}$: 11\n",
    "- $\\texttt{ice cream sold}$: 120\n",
    "- $\\texttt{misery index}$: 15\n",
    "- $\\texttt{temperature}$: 70 degrees F\n",
    "- $\\texttt{humidity}$: 83\n",
    "- $\\texttt{pizzas sold}$: 5500\n",
    "- $\\texttt{pressure}$: 850 millibar \n",
    "- $\\texttt{octopuses}$: 6\n",
    "- $\\texttt{Zach's shoe size}$: 9.5\n",
    "- $\\texttt{Rachel's shoe size}$: 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57.19\n"
     ]
    }
   ],
   "source": [
    "#Your code here.\n",
    "\n",
    "\n",
    "new_features = {\"const\": 1, \n",
    "                \"taunts\": 47, \"clouds\": 0.8, \"precipitation\": 1, \n",
    "                \"earthquake\": 5, \"shark attacks\": 11, \"ice cream sold\": 120, \n",
    "                \"misery index\": 15, \"temperature\": 70, \\\n",
    "        \"humidity\": 83, \"pizzas sold\": 5500, \"pressure\": 850, \"octopuses\": 6, \\\n",
    "        \"Dans shoe size\": 9.5, \"Tonys shoe size\": 9}\n",
    "\n",
    "yhat = 0 \n",
    "for i, j in zip(reduced_model.params.index, reduced_model.params):\n",
    "    yhat += new_features[i] * j\n",
    "print(np.round(yhat, decimals = 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part G:** Consider the model you used in Part E, and consider the fact that you are trying to predict **sharknado hazard**. What is one critical drawback to the MLR model (or any MLR model) for predicting shardnado hazard? What are some modifications that could improve on this issue?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
